{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KdYM2H3IVXnQ"
      ],
      "authorship_tag": "ABX9TyNTGf6yEB7cjL4YngCo4fky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olusipedaniel/zero-to-mastery-exercises/blob/main/01_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "  1. Building a larger model (how does one with 4 dense layers go?).\n",
        "  2. Increasing the number of units in each layer.\n",
        "  3. Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "  4. What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "4. Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it."
      ],
      "metadata": {
        "id": "JHqTU4DxQ0EF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Create your own regression dataset and build, fit a model to it."
      ],
      "metadata": {
        "id": "ztzdk3uqRRfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing python libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Z2bmSuDVRXgw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Independent variable\n",
        "X=tf.range(0,500,5)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX-RaQXqRoKd",
        "outputId": "ce89317a-fc8d-477a-9b77-48308643fd96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
              "array([  0,   5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,\n",
              "        65,  70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125,\n",
              "       130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190,\n",
              "       195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255,\n",
              "       260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320,\n",
              "       325, 330, 335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385,\n",
              "       390, 395, 400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450,\n",
              "       455, 460, 465, 470, 475, 480, 485, 490, 495], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Dependent variable\n",
        "y=X+10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcrlgAZ1R1Ye",
        "outputId": "f0364806-2091-4165-dbd7-cb2d0d92d60b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
              "array([ 10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,  70,\n",
              "        75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
              "       140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200,\n",
              "       205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265,\n",
              "       270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320, 325, 330,\n",
              "       335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385, 390, 395,\n",
              "       400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460,\n",
              "       465, 470, 475, 480, 485, 490, 495, 500, 505], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing datasets\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "a0sgLfGHR3q1",
        "outputId": "edd561fa-b989-4e3a-e426-1e8b1ee2c7c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3471e84550>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting our dataset into train and test data manually(train data is 80% of the whole dataset)\n",
        "X_train=X[:80]\n",
        "y_train=y[:80]\n",
        "\n",
        "X_test=X[80:]\n",
        "y_test=y[80:]\n",
        "\n",
        "X_train,X_test,y_train,y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-5V8aO7R6lF",
        "outputId": "7e428caf-0dba-4884-d009-6b13bdb3e736"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(80,), dtype=int32, numpy=\n",
              " array([  0,   5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,\n",
              "         65,  70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125,\n",
              "        130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190,\n",
              "        195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255,\n",
              "        260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320,\n",
              "        325, 330, 335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385,\n",
              "        390, 395], dtype=int32)>, <tf.Tensor: shape=(20,), dtype=int32, numpy=\n",
              " array([400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460,\n",
              "        465, 470, 475, 480, 485, 490, 495], dtype=int32)>, <tf.Tensor: shape=(80,), dtype=int32, numpy=\n",
              " array([ 10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,  70,\n",
              "         75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130, 135,\n",
              "        140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200,\n",
              "        205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265,\n",
              "        270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320, 325, 330,\n",
              "        335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385, 390, 395,\n",
              "        400, 405], dtype=int32)>, <tf.Tensor: shape=(20,), dtype=int32, numpy=\n",
              " array([410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470,\n",
              "        475, 480, 485, 490, 495, 500, 505], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing training and test set\n",
        "# Setting figsize\n",
        "plt.figure(figsize=(10,7))\n",
        "# Plotting training set in red\n",
        "plt.scatter(X_train,y_train,c=\"r\",label=\"Training data\")\n",
        "# Plotting test set in blue\n",
        "plt.scatter(X_test,y_test,c=\"b\",label=\"Testing data\")\n",
        "# Visualizing training and test set\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "_nDO2CckR98e",
        "outputId": "7f48a0e9-2f87-4e9c-97cf-92d2c6ec43b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model\n",
        "model_1=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                 optimizer=tf.keras.optimizers.SGD(),\n",
        "                 metrics=\"mae\")\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train,axis=-1),y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RIleO-0SA7K",
        "outputId": "790a8071-f170-4122-8eee-559bc9367c16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 5ms/step - loss: 172.9119 - mae: 172.9119\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 228.7553 - mae: 228.7553\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 169.5016 - mae: 169.5016\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 216.5392 - mae: 216.5392\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 169.1617 - mae: 169.1617\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 219.2156 - mae: 219.2156\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 187.0981 - mae: 187.0981\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 194.6056 - mae: 194.6056\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 207.2052 - mae: 207.2052\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 168.2179 - mae: 168.2179\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 214.2926 - mae: 214.2926\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 200.3763 - mae: 200.3763\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 183.4043 - mae: 183.4043\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 203.3072 - mae: 203.3072\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 184.9594 - mae: 184.9594\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 200.1373 - mae: 200.1373\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 200.0216 - mae: 200.0216\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 183.9703 - mae: 183.9703\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 198.2363 - mae: 198.2363\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 188.8096 - mae: 188.8096\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 196.9096 - mae: 196.9096\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 186.8350 - mae: 186.8350\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 201.2516 - mae: 201.2516\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 182.8424 - mae: 182.8424\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 205.7680 - mae: 205.7680\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 187.8657 - mae: 187.8657\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 208.4519 - mae: 208.4519\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 183.9549 - mae: 183.9549\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 210.9745 - mae: 210.9745\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 114.5161 - mae: 114.5161\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 174.3192 - mae: 174.3192\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 229.5026 - mae: 229.5026\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 78.7288 - mae: 78.7288\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 201.0218 - mae: 201.0218\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 185.6511 - mae: 185.6511\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 202.8526 - mae: 202.8526\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 218.8163 - mae: 218.8163\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 148.4619 - mae: 148.4619\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 209.4393 - mae: 209.4393\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 161.7257 - mae: 161.7257\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 228.4334 - mae: 228.4334\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 175.4158 - mae: 175.4158\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 209.5233 - mae: 209.5233\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 169.9048 - mae: 169.9048\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 227.0489 - mae: 227.0489\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 184.5216 - mae: 184.5216\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 197.9513 - mae: 197.9513\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 186.2096 - mae: 186.2096\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 196.5090 - mae: 196.5090\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 152.3189 - mae: 152.3189\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 246.1152 - mae: 246.1152\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 172.9760 - mae: 172.9760\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 212.8921 - mae: 212.8921\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 160.1690 - mae: 160.1690\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 223.9173 - mae: 223.9173\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 154.7633 - mae: 154.7633\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 249.1617 - mae: 249.1617\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 189.8954 - mae: 189.8954\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 224.7445 - mae: 224.7445\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 159.0174 - mae: 159.0174\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 234.5209 - mae: 234.5209\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 146.4780 - mae: 146.4780\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 269.3125 - mae: 269.3125\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 181.5898 - mae: 181.5898\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 205.5235 - mae: 205.5235\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 157.1584 - mae: 157.1584\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 237.6122 - mae: 237.6122\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 162.6754 - mae: 162.6754\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 221.5145 - mae: 221.5145\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 172.0238 - mae: 172.0238\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 217.1151 - mae: 217.1151\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 169.8488 - mae: 169.8488\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 210.2200 - mae: 210.2200\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 158.6752 - mae: 158.6752\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 219.4027 - mae: 219.4027\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 185.4606 - mae: 185.4606\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 199.5844 - mae: 199.5844\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 187.4905 - mae: 187.4905\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 196.8505 - mae: 196.8505\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 177.2442 - mae: 177.2442\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 271.6068 - mae: 271.6068\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 143.6423 - mae: 143.6423\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 214.1897 - mae: 214.1897\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 191.1980 - mae: 191.1980\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 210.1713 - mae: 210.1713\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 177.7469 - mae: 177.7469\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 230.9422 - mae: 230.9422\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 174.5685 - mae: 174.5685\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 229.1025 - mae: 229.1025\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 169.5462 - mae: 169.5462\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 206.2427 - mae: 206.2427\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 216.0741 - mae: 216.0741\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 193.9963 - mae: 193.9963\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 189.2894 - mae: 189.2894\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 200.1205 - mae: 200.1205\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 163.2928 - mae: 163.2928\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 216.6965 - mae: 216.6965\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 198.7664 - mae: 198.7664\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 152.4864 - mae: 152.4864\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 269.4380 - mae: 269.4380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3470fa53d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating model_1\n",
        "model_1.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IDxUry4SGyb",
        "outputId": "4685d4d6-f933-4173-dde3-58cfff2bb54d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 139ms/step - loss: 157.8627 - mae: 157.8627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[157.86265563964844, 157.86265563964844]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions with model_1 and turning it into a tensor\n",
        "y_pred=model_1.predict(X_test)\n",
        "tf.constant(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6ySv-XuSaMc",
        "outputId": "172754b0-ef30-411e-9f06-1a4d05db4cd1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20, 1), dtype=float32, numpy=\n",
              "array([[550.06213],\n",
              "       [556.9359 ],\n",
              "       [563.80963],\n",
              "       [570.68335],\n",
              "       [577.5571 ],\n",
              "       [584.43085],\n",
              "       [591.30457],\n",
              "       [598.17834],\n",
              "       [605.05206],\n",
              "       [611.9258 ],\n",
              "       [618.7995 ],\n",
              "       [625.6733 ],\n",
              "       [632.547  ],\n",
              "       [639.4207 ],\n",
              "       [646.2945 ],\n",
              "       [653.1682 ],\n",
              "       [660.04193],\n",
              "       [666.9157 ],\n",
              "       [673.7894 ],\n",
              "       [680.66315]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3hcoqVtSioe",
        "outputId": "ea22669c-d57f-4293-b105-be651000a20c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int32, numpy=\n",
              "array([410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470,\n",
              "       475, 480, 485, 490, 495, 500, 505], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a funtion to plot predictions\n",
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \n",
        "  # Setting figsize\n",
        "  plt.figure(figsize=(10,7))\n",
        "  # Plot training data in Green\n",
        "  plt.scatter(X_train,y_train,c=\"g\",label=\"Training data\")\n",
        "  # Plot test data in blue\n",
        "  plt.scatter(X_test,y_test,c=\"b\",label=\"Test data\")\n",
        "  # Plot predictions in red\n",
        "  plt.scatter(X_test,predictions,c=\"r\",label=\"predictions\")"
      ],
      "metadata": {
        "id": "asvhcv_iSlob"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting predictions\n",
        "plot_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "mFufZSX7SoQ1",
        "outputId": "3961b85e-11a1-4676-fb6f-8e63d4ca821d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?"
      ],
      "metadata": {
        "id": "AEL7YPtoSsAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model\n",
        "model_2=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(30),\n",
        "  tf.keras.layers.Dense(30),\n",
        "  tf.keras.layers.Dense(30),\n",
        "  tf.keras.layers.Dense(30),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                   optimizer=tf.keras.optimizers.Adam(),\n",
        "                   metrics=\"mae\")\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train,axis=-1),y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRx-RGKBR7Xj",
        "outputId": "3840f5a8-c12f-45d4-b8c1-8e0958de843b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 5ms/step - loss: 268.0128 - mae: 268.0128\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 210.6956 - mae: 210.6956\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 146.7419 - mae: 146.7419\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 86.5237 - mae: 86.5237\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 22.3681 - mae: 22.3681\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 34.8800 - mae: 34.8800\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 40.4867 - mae: 40.4867\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 19.0001 - mae: 19.0001\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 11.7356 - mae: 11.7356\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 19.1040 - mae: 19.1040\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 8.8368 - mae: 8.8368\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 11.1268 - mae: 11.1268\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 7.6235 - mae: 7.6235\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 7.8389 - mae: 7.8389\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 5.6863 - mae: 5.6863\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 5.7853 - mae: 5.7853\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.4474 - mae: 4.4474\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.3951 - mae: 4.3951\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 4.2359 - mae: 4.2359\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9651 - mae: 3.9651\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.9331 - mae: 3.9331\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 4.1604 - mae: 4.1604\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.5149 - mae: 4.5149\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.2628 - mae: 4.2628\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4145 - mae: 4.4145\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1977 - mae: 4.1977\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.1833 - mae: 4.1833\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9106 - mae: 3.9106\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1612 - mae: 4.1612\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8319 - mae: 3.8319\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7867 - mae: 3.7867\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7742 - mae: 3.7742\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1641 - mae: 4.1641\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9912 - mae: 3.9912\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5344 - mae: 4.5344\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.8178 - mae: 3.8178\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.1337 - mae: 4.1337\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8424 - mae: 3.8424\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8692 - mae: 3.8692\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.6214 - mae: 3.6214\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.7435 - mae: 3.7435\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0284 - mae: 4.0284\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4815 - mae: 4.4815\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.5634 - mae: 3.5634\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5310 - mae: 3.5310\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.0850 - mae: 4.0850\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 4.2803 - mae: 4.2803\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4215 - mae: 4.4215\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.9992 - mae: 3.9992\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7000 - mae: 3.7000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.5763 - mae: 3.5763\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.7354 - mae: 3.7354\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 3.8257 - mae: 3.8257\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.8666 - mae: 3.8666\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4773 - mae: 4.4773\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5589 - mae: 3.5589\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.3204 - mae: 3.3204\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5911 - mae: 3.5911\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 3.2892 - mae: 3.2892\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.7098 - mae: 3.7098\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.0745 - mae: 4.0745\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5715 - mae: 4.5715\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 4.1057 - mae: 4.1057\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.2455 - mae: 4.2455\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.7046 - mae: 3.7046\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.4908 - mae: 3.4908\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3430 - mae: 3.3430\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4224 - mae: 4.4224\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 3.5238 - mae: 3.5238\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9524 - mae: 3.9524\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.1210 - mae: 4.1210\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.5883 - mae: 4.5883\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.5478 - mae: 3.5478\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.6579 - mae: 4.6579\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4825 - mae: 3.4825\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 3.6372 - mae: 3.6372\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.9468 - mae: 3.9468\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.4827 - mae: 3.4827\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.5636 - mae: 3.5636\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.1432 - mae: 3.1432\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1561 - mae: 3.1561\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.0156 - mae: 3.0156\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.9089 - mae: 2.9089\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.8845 - mae: 2.8845\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.1188 - mae: 3.1188\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.9517 - mae: 2.9517\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.2909 - mae: 3.2909\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.6999 - mae: 3.6999\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.8159 - mae: 4.8159\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.1221 - mae: 4.1221\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 3.3546 - mae: 3.3546\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.9451 - mae: 2.9451\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.1458 - mae: 3.1458\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3.1557 - mae: 3.1557\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.3834 - mae: 3.3834\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 3.4735 - mae: 3.4735\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 3.6875 - mae: 3.6875\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 4.4780 - mae: 4.4780\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.4238 - mae: 4.4238\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 4.0787 - mae: 4.0787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3470ead410>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating model_2\n",
        "model_2.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRi2mfsVS6OR",
        "outputId": "6550c2d3-5d75-44bb-b171-34b48f0466aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step - loss: 2.8076 - mae: 2.8076\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.8076109886169434, 2.8076109886169434]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions with model_2 and converting it to a tensor\n",
        "y_pred_2=model_2.predict(X_test)\n",
        "tf.constant(y_pred_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsTvZC6nS_cR",
        "outputId": "96e4e246-1d00-4ff7-e14c-b515566ac602"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20, 1), dtype=float32, numpy=\n",
              "array([[411.88165],\n",
              "       [416.97916],\n",
              "       [422.0766 ],\n",
              "       [427.1741 ],\n",
              "       [432.2716 ],\n",
              "       [437.369  ],\n",
              "       [442.46655],\n",
              "       [447.5639 ],\n",
              "       [452.66144],\n",
              "       [457.75894],\n",
              "       [462.85638],\n",
              "       [467.95383],\n",
              "       [473.0513 ],\n",
              "       [478.14874],\n",
              "       [483.2462 ],\n",
              "       [488.3436 ],\n",
              "       [493.44107],\n",
              "       [498.5385 ],\n",
              "       [503.63608],\n",
              "       [508.73352]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQl6fUiqTET0",
        "outputId": "bd7c05a5-ec84-44b7-d4de-68ef9dd199d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int32, numpy=\n",
              "array([410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470,\n",
              "       475, 480, 485, 490, 495, 500, 505], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting model_2 predictions\n",
        "plot_predictions(predictions=y_pred_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "UtPfMiPdTJ__",
        "outputId": "10e0afca-4fa1-40d5-e222-093e63b2eee0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Try and improve the results we got on the insurance dataset, some things you might want to try include:"
      ],
      "metadata": {
        "id": "sUuQSy6oTMXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing insurance data\n",
        "insurance=pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vObWWmCLUCUP",
        "outputId": "1567fb2f-364b-4388-d7e1-bafd79535650"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfefb592-4020-416a-b4ec-78f1e9cf8fb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfefb592-4020-416a-b4ec-78f1e9cf8fb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfefb592-4020-416a-b4ec-78f1e9cf8fb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfefb592-4020-416a-b4ec-78f1e9cf8fb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding categorial variables\n",
        "insurance_data=pd.get_dummies(insurance)\n",
        "insurance_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rdLRAMqPUFvT",
        "outputId": "80920651-6d70-42c8-875e-57a76f3a62fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
              "0      19  27.900         0  16884.92400           1         0          0   \n",
              "1      18  33.770         1   1725.55230           0         1          1   \n",
              "2      28  33.000         3   4449.46200           0         1          1   \n",
              "3      33  22.705         0  21984.47061           0         1          1   \n",
              "4      32  28.880         0   3866.85520           0         1          1   \n",
              "...   ...     ...       ...          ...         ...       ...        ...   \n",
              "1333   50  30.970         3  10600.54830           0         1          1   \n",
              "1334   18  31.920         0   2205.98080           1         0          1   \n",
              "1335   18  36.850         0   1629.83350           1         0          1   \n",
              "1336   21  25.800         0   2007.94500           1         0          1   \n",
              "1337   61  29.070         0  29141.36030           1         0          0   \n",
              "\n",
              "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
              "0              1                 0                 0                 0   \n",
              "1              0                 0                 0                 1   \n",
              "2              0                 0                 0                 1   \n",
              "3              0                 0                 1                 0   \n",
              "4              0                 0                 1                 0   \n",
              "...          ...               ...               ...               ...   \n",
              "1333           0                 0                 1                 0   \n",
              "1334           0                 1                 0                 0   \n",
              "1335           0                 0                 0                 1   \n",
              "1336           0                 0                 0                 0   \n",
              "1337           1                 0                 1                 0   \n",
              "\n",
              "      region_southwest  \n",
              "0                    1  \n",
              "1                    0  \n",
              "2                    0  \n",
              "3                    0  \n",
              "4                    0  \n",
              "...                ...  \n",
              "1333                 0  \n",
              "1334                 0  \n",
              "1335                 0  \n",
              "1336                 1  \n",
              "1337                 0  \n",
              "\n",
              "[1338 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e073de83-0eb4-4fe9-b530-cc95060bc892\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>10600.54830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>2205.98080</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1629.83350</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.94500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>29141.36030</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e073de83-0eb4-4fe9-b530-cc95060bc892')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e073de83-0eb4-4fe9-b530-cc95060bc892 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e073de83-0eb4-4fe9-b530-cc95060bc892');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X & y variable\n",
        "X=insurance_data.drop(\"charges\", axis=1)\n",
        "y=insurance_data[\"charges\"]"
      ],
      "metadata": {
        "id": "YzPnc7e8UIjT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing X & y\n",
        "X.head(),y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG0SMDsUUMAs",
        "outputId": "d3261cbe-c04e-4802-9da4-b884864967a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              " 0   19  27.900         0           1         0          0           1   \n",
              " 1   18  33.770         1           0         1          1           0   \n",
              " 2   28  33.000         3           0         1          1           0   \n",
              " 3   33  22.705         0           0         1          1           0   \n",
              " 4   32  28.880         0           0         1          1           0   \n",
              " \n",
              "    region_northeast  region_northwest  region_southeast  region_southwest  \n",
              " 0                 0                 0                 0                 1  \n",
              " 1                 0                 0                 1                 0  \n",
              " 2                 0                 0                 1                 0  \n",
              " 3                 0                 1                 0                 0  \n",
              " 4                 0                 1                 0                 0  ,\n",
              " 0    16884.92400\n",
              " 1     1725.55230\n",
              " 2     4449.46200\n",
              " 3    21984.47061\n",
              " 4     3866.85520\n",
              " Name: charges, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting data into training and test data\n",
        "# Importing test_train_split from sklearn library\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "VfBikcLVUOKS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leW0Yi-8UUFa",
        "outputId": "595a022a-fc01-4d7e-a7e7-20af26282e4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 11), (268, 11), (1070,), (268,))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a larger model (how does one with 4 dense layers go?).\n",
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Build our model\n",
        "insurance_model=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile our model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.Adam(),\n",
        "                        metrics=\"mae\")\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model.fit(X_train,y_train,epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mEr_869UWvE",
        "outputId": "ba614ce5-36be-4503-e3d5-08a8fe4dae01"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 1s 4ms/step - loss: 11726.8760 - mae: 11726.8760\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7458.9053 - mae: 7458.9053\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7137.1802 - mae: 7137.1802\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6899.0356 - mae: 6899.0356\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6756.6240 - mae: 6756.6240\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6686.3789 - mae: 6686.3789\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6685.2388 - mae: 6685.2388\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6570.2100 - mae: 6570.2100\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6527.1128 - mae: 6527.1128\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6457.4448 - mae: 6457.4448\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6414.0698 - mae: 6414.0698\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6358.7080 - mae: 6358.7080\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6212.9121 - mae: 6212.9121\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6082.6396 - mae: 6082.6396\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5863.5317 - mae: 5863.5317\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5513.2456 - mae: 5513.2456\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4897.4976 - mae: 4897.4976\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4188.1733 - mae: 4188.1733\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3981.3672 - mae: 3981.3672\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3959.9678 - mae: 3959.9678\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3899.7668 - mae: 3899.7668\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3906.4475 - mae: 3906.4475\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3871.2417 - mae: 3871.2417\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3910.2097 - mae: 3910.2097\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3883.1965 - mae: 3883.1965\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3816.9143 - mae: 3816.9143\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3816.9578 - mae: 3816.9578\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3772.1169 - mae: 3772.1169\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3833.5383 - mae: 3833.5383\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3769.8374 - mae: 3769.8374\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3770.7192 - mae: 3770.7192\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3738.4961 - mae: 3738.4961\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3733.3135 - mae: 3733.3135\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3789.0256 - mae: 3789.0256\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3699.2705 - mae: 3699.2705\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3717.2517 - mae: 3717.2517\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3701.5007 - mae: 3701.5007\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3673.8691 - mae: 3673.8691\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3694.0298 - mae: 3694.0298\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3650.9810 - mae: 3650.9810\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3650.5884 - mae: 3650.5884\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3637.7744 - mae: 3637.7744\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3637.3435 - mae: 3637.3435\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3620.0286 - mae: 3620.0286\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3602.5669 - mae: 3602.5669\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3604.0391 - mae: 3604.0391\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3614.3745 - mae: 3614.3745\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3609.1714 - mae: 3609.1714\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3642.2039 - mae: 3642.2039\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3633.4563 - mae: 3633.4563\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3558.2363 - mae: 3558.2363\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3568.2529 - mae: 3568.2529\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3544.3726 - mae: 3544.3726\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3613.8389 - mae: 3613.8389\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3632.9810 - mae: 3632.9810\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3570.6089 - mae: 3570.6089\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3568.3513 - mae: 3568.3513\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3714.6377 - mae: 3714.6377\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3557.9719 - mae: 3557.9719\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3552.6724 - mae: 3552.6724\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3575.9282 - mae: 3575.9282\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3561.4048 - mae: 3561.4048\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3525.3999 - mae: 3525.3999\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3533.7305 - mae: 3533.7305\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3545.5076 - mae: 3545.5076\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3705.4707 - mae: 3705.4707\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3565.7314 - mae: 3565.7314\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3609.1914 - mae: 3609.1914\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3564.7966 - mae: 3564.7966\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3537.4724 - mae: 3537.4724\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3530.0771 - mae: 3530.0771\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3598.6104 - mae: 3598.6104\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3539.5198 - mae: 3539.5198\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3533.8450 - mae: 3533.8450\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3548.0571 - mae: 3548.0571\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3560.3687 - mae: 3560.3687\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3697.8501 - mae: 3697.8501\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3572.6440 - mae: 3572.6440\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3570.5071 - mae: 3570.5071\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3536.5518 - mae: 3536.5518\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3586.1194 - mae: 3586.1194\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3642.7771 - mae: 3642.7771\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3545.0461 - mae: 3545.0461\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3527.1624 - mae: 3527.1624\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3522.5981 - mae: 3522.5981\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3502.2302 - mae: 3502.2302\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3562.0237 - mae: 3562.0237\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3517.7021 - mae: 3517.7021\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3518.2891 - mae: 3518.2891\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3515.8289 - mae: 3515.8289\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3520.3804 - mae: 3520.3804\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3585.2161 - mae: 3585.2161\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3615.8716 - mae: 3615.8716\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3612.0823 - mae: 3612.0823\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3550.1250 - mae: 3550.1250\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3494.6277 - mae: 3494.6277\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3612.5676 - mae: 3612.5676\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3561.4709 - mae: 3561.4709\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3519.7932 - mae: 3519.7932\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3532.2908 - mae: 3532.2908\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3512.1199 - mae: 3512.1199\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3519.5032 - mae: 3519.5032\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3508.2073 - mae: 3508.2073\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3506.1609 - mae: 3506.1609\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3527.8025 - mae: 3527.8025\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3534.5461 - mae: 3534.5461\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3530.6196 - mae: 3530.6196\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3589.3774 - mae: 3589.3774\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3530.4321 - mae: 3530.4321\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3511.1885 - mae: 3511.1885\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3567.1340 - mae: 3567.1340\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3545.7727 - mae: 3545.7727\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3520.8098 - mae: 3520.8098\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3529.9873 - mae: 3529.9873\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3531.7344 - mae: 3531.7344\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3587.4744 - mae: 3587.4744\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3530.3555 - mae: 3530.3555\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3494.8948 - mae: 3494.8948\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3677.4775 - mae: 3677.4775\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3535.0681 - mae: 3535.0681\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3516.2019 - mae: 3516.2019\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3566.1946 - mae: 3566.1946\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3569.7056 - mae: 3569.7056\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3526.3528 - mae: 3526.3528\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3571.6807 - mae: 3571.6807\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3535.3628 - mae: 3535.3628\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3554.6421 - mae: 3554.6421\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3529.2581 - mae: 3529.2581\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3558.7473 - mae: 3558.7473\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3602.7832 - mae: 3602.7832\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3513.8416 - mae: 3513.8416\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.3171 - mae: 3546.3171\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3521.6887 - mae: 3521.6887\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3530.4470 - mae: 3530.4470\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3579.6646 - mae: 3579.6646\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3565.1482 - mae: 3565.1482\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3524.1829 - mae: 3524.1829\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3562.9226 - mae: 3562.9226\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3613.8225 - mae: 3613.8225\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3529.4954 - mae: 3529.4954\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3540.8196 - mae: 3540.8196\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3531.0801 - mae: 3531.0801\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3509.2498 - mae: 3509.2498\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3508.3748 - mae: 3508.3748\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3543.0940 - mae: 3543.0940\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3579.4319 - mae: 3579.4319\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3569.0762 - mae: 3569.0762\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3544.5229 - mae: 3544.5229\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3507.5591 - mae: 3507.5591\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3491.8149 - mae: 3491.8149\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3521.5317 - mae: 3521.5317\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3561.9812 - mae: 3561.9812\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3612.9229 - mae: 3612.9229\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3597.1702 - mae: 3597.1702\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3547.6470 - mae: 3547.6470\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3529.3357 - mae: 3529.3357\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3503.5613 - mae: 3503.5613\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3544.5012 - mae: 3544.5012\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3500.8086 - mae: 3500.8086\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3631.1375 - mae: 3631.1375\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3501.7834 - mae: 3501.7834\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3507.9734 - mae: 3507.9734\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3555.3562 - mae: 3555.3562\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3535.4536 - mae: 3535.4536\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3632.9492 - mae: 3632.9492\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3565.3738 - mae: 3565.3738\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3572.4902 - mae: 3572.4902\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3623.8516 - mae: 3623.8516\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3511.2317 - mae: 3511.2317\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3514.1152 - mae: 3514.1152\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3525.3555 - mae: 3525.3555\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3495.7458 - mae: 3495.7458\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3539.8367 - mae: 3539.8367\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3502.6008 - mae: 3502.6008\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3524.4102 - mae: 3524.4102\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3506.5125 - mae: 3506.5125\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3530.1721 - mae: 3530.1721\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3547.4434 - mae: 3547.4434\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3536.2832 - mae: 3536.2832\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3551.5027 - mae: 3551.5027\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3552.2690 - mae: 3552.2690\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3570.5469 - mae: 3570.5469\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3637.4739 - mae: 3637.4739\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3690.4341 - mae: 3690.4341\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3502.4897 - mae: 3502.4897\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3565.7637 - mae: 3565.7637\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3589.0151 - mae: 3589.0151\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3514.3462 - mae: 3514.3462\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3512.4375 - mae: 3512.4375\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3504.5417 - mae: 3504.5417\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3515.7935 - mae: 3515.7935\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3517.9780 - mae: 3517.9780\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3523.0093 - mae: 3523.0093\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3547.8911 - mae: 3547.8911\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3567.2693 - mae: 3567.2693\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3642.2551 - mae: 3642.2551\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3519.5752 - mae: 3519.5752\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3530.9004 - mae: 3530.9004\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3519.5542 - mae: 3519.5542\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3520.3618 - mae: 3520.3618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f346ff10a90>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating insurance_model\n",
        "insurance_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxaULP4IUZaw",
        "outputId": "d45cc82e-f853-47f0-97d7-8baff330fd16"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3226.3079 - mae: 3226.3079\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3226.307861328125, 3226.307861328125]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Increasing the number of units in each layer.\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1.Build our model\n",
        "insurance_model_2=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# 2. Compile our model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=\"mae\")\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_2.fit(X_train,y_train,epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU5nOp23Uc_f",
        "outputId": "d635ce3b-9dc8-4068-b84f-ec7b785da029"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 1s 3ms/step - loss: 10198.5410 - mae: 10198.5410\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7366.7866 - mae: 7366.7866\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6923.7798 - mae: 6923.7798\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6723.9546 - mae: 6723.9546\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6671.3164 - mae: 6671.3164\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6570.3667 - mae: 6570.3667\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6561.6396 - mae: 6561.6396\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6525.0029 - mae: 6525.0029\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6345.7827 - mae: 6345.7827\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6240.8315 - mae: 6240.8315\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6009.2607 - mae: 6009.2607\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5572.2456 - mae: 5572.2456\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4619.3071 - mae: 4619.3071\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4160.1587 - mae: 4160.1587\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4143.0103 - mae: 4143.0103\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4096.0049 - mae: 4096.0049\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3875.7029 - mae: 3875.7029\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3847.8481 - mae: 3847.8481\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3942.2639 - mae: 3942.2639\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3884.7061 - mae: 3884.7061\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3902.7366 - mae: 3902.7366\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3861.9568 - mae: 3861.9568\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3839.5603 - mae: 3839.5603\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3786.1921 - mae: 3786.1921\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3832.4744 - mae: 3832.4744\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3867.7485 - mae: 3867.7485\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3795.9365 - mae: 3795.9365\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3808.2605 - mae: 3808.2605\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3758.9653 - mae: 3758.9653\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3869.2124 - mae: 3869.2124\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3808.6282 - mae: 3808.6282\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3693.7385 - mae: 3693.7385\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3679.9756 - mae: 3679.9756\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3714.9561 - mae: 3714.9561\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3709.2981 - mae: 3709.2981\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3715.6248 - mae: 3715.6248\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3663.9358 - mae: 3663.9358\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3628.3528 - mae: 3628.3528\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3586.7952 - mae: 3586.7952\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3637.6865 - mae: 3637.6865\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3590.7292 - mae: 3590.7292\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3650.6060 - mae: 3650.6060\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3695.7451 - mae: 3695.7451\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3618.3037 - mae: 3618.3037\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3579.9097 - mae: 3579.9097\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3581.0906 - mae: 3581.0906\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3596.5784 - mae: 3596.5784\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3610.1604 - mae: 3610.1604\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3585.9351 - mae: 3585.9351\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3662.6055 - mae: 3662.6055\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3588.3879 - mae: 3588.3879\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3611.1016 - mae: 3611.1016\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3578.0850 - mae: 3578.0850\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3639.6892 - mae: 3639.6892\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3665.2041 - mae: 3665.2041\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3544.2566 - mae: 3544.2566\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3581.7646 - mae: 3581.7646\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3581.8096 - mae: 3581.8096\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3566.3967 - mae: 3566.3967\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3606.1199 - mae: 3606.1199\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3618.0100 - mae: 3618.0100\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3533.2947 - mae: 3533.2947\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3522.9570 - mae: 3522.9570\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3549.9998 - mae: 3549.9998\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3567.9387 - mae: 3567.9387\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3705.4880 - mae: 3705.4880\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3596.8723 - mae: 3596.8723\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3667.2358 - mae: 3667.2358\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3572.2505 - mae: 3572.2505\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3556.6348 - mae: 3556.6348\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3588.9043 - mae: 3588.9043\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3557.3579 - mae: 3557.3579\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3577.3320 - mae: 3577.3320\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3610.5403 - mae: 3610.5403\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3557.2239 - mae: 3557.2239\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3586.5513 - mae: 3586.5513\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3618.8184 - mae: 3618.8184\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3706.0801 - mae: 3706.0801\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3685.0166 - mae: 3685.0166\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3557.5945 - mae: 3557.5945\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3689.0349 - mae: 3689.0349\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3770.3452 - mae: 3770.3452\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3646.8452 - mae: 3646.8452\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3572.3230 - mae: 3572.3230\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3528.9724 - mae: 3528.9724\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3514.5481 - mae: 3514.5481\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3626.6206 - mae: 3626.6206\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3531.3950 - mae: 3531.3950\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3591.9470 - mae: 3591.9470\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3534.0588 - mae: 3534.0588\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3532.0574 - mae: 3532.0574\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3632.2876 - mae: 3632.2876\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3650.7837 - mae: 3650.7837\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3706.5752 - mae: 3706.5752\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3609.0527 - mae: 3609.0527\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3503.6646 - mae: 3503.6646\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3695.4902 - mae: 3695.4902\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3591.5334 - mae: 3591.5334\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3531.6501 - mae: 3531.6501\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3556.4944 - mae: 3556.4944\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3515.8423 - mae: 3515.8423\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3557.3201 - mae: 3557.3201\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3514.2375 - mae: 3514.2375\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3520.0706 - mae: 3520.0706\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3538.0376 - mae: 3538.0376\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3515.7253 - mae: 3515.7253\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3548.6904 - mae: 3548.6904\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3545.1870 - mae: 3545.1870\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3539.8555 - mae: 3539.8555\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3569.5044 - mae: 3569.5044\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3608.1765 - mae: 3608.1765\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3555.2749 - mae: 3555.2749\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3544.1646 - mae: 3544.1646\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3614.6829 - mae: 3614.6829\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3569.3655 - mae: 3569.3655\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3669.8777 - mae: 3669.8777\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3547.2908 - mae: 3547.2908\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3516.7651 - mae: 3516.7651\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3649.4067 - mae: 3649.4067\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3574.2485 - mae: 3574.2485\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3542.4753 - mae: 3542.4753\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3566.7407 - mae: 3566.7407\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3796.0332 - mae: 3796.0332\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3680.2302 - mae: 3680.2302\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3565.0549 - mae: 3565.0549\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3579.3252 - mae: 3579.3252\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3532.7432 - mae: 3532.7432\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3582.0808 - mae: 3582.0808\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3599.5552 - mae: 3599.5552\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3617.5554 - mae: 3617.5554\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3523.9158 - mae: 3523.9158\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3603.4314 - mae: 3603.4314\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3569.2329 - mae: 3569.2329\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3576.0396 - mae: 3576.0396\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3558.5947 - mae: 3558.5947\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3574.5190 - mae: 3574.5190\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3593.9531 - mae: 3593.9531\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3676.7605 - mae: 3676.7605\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3615.1931 - mae: 3615.1931\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3549.5896 - mae: 3549.5896\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3631.4829 - mae: 3631.4829\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3552.6890 - mae: 3552.6890\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3555.8496 - mae: 3555.8496\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3528.6863 - mae: 3528.6863\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3593.6790 - mae: 3593.6790\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3594.9756 - mae: 3594.9756\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3583.4365 - mae: 3583.4365\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3534.4106 - mae: 3534.4106\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3554.4854 - mae: 3554.4854\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3512.8337 - mae: 3512.8337\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3558.2742 - mae: 3558.2742\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3567.6157 - mae: 3567.6157\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 3574.8794 - mae: 3574.8794\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 3653.1819 - mae: 3653.1819\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3586.2512 - mae: 3586.2512\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3563.4380 - mae: 3563.4380\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3541.5229 - mae: 3541.5229\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3593.2302 - mae: 3593.2302\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3517.4561 - mae: 3517.4561\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3602.3262 - mae: 3602.3262\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3537.2361 - mae: 3537.2361\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3548.8831 - mae: 3548.8831\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3559.2771 - mae: 3559.2771\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3535.6060 - mae: 3535.6060\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3660.7295 - mae: 3660.7295\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3615.9158 - mae: 3615.9158\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3564.4241 - mae: 3564.4241\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3663.5378 - mae: 3663.5378\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 3541.9863 - mae: 3541.9863\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3541.1172 - mae: 3541.1172\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3554.5166 - mae: 3554.5166\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3524.5105 - mae: 3524.5105\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3517.9417 - mae: 3517.9417\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3523.4194 - mae: 3523.4194\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3546.5752 - mae: 3546.5752\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3559.3250 - mae: 3559.3250\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3550.1594 - mae: 3550.1594\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3555.0161 - mae: 3555.0161\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3669.8401 - mae: 3669.8401\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3603.2886 - mae: 3603.2886\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3549.9153 - mae: 3549.9153\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3571.5112 - mae: 3571.5112\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3675.4194 - mae: 3675.4194\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3758.4878 - mae: 3758.4878\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3532.9343 - mae: 3532.9343\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3572.8767 - mae: 3572.8767\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3621.6252 - mae: 3621.6252\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3522.3037 - mae: 3522.3037\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3541.2810 - mae: 3541.2810\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3530.3794 - mae: 3530.3794\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3586.0962 - mae: 3586.0962\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3581.7878 - mae: 3581.7878\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3565.0952 - mae: 3565.0952\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3575.3936 - mae: 3575.3936\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3613.4585 - mae: 3613.4585\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 3676.2478 - mae: 3676.2478\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3549.1294 - mae: 3549.1294\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 3565.5024 - mae: 3565.5024\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 3545.2534 - mae: 3545.2534\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 3554.2336 - mae: 3554.2336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f346fd56110>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating insurance_model_2\n",
        "insurance_model_2.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOyw8mVtUhsy",
        "outputId": "e7ff7d6a-9a01-448c-b54b-314139f957a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 4ms/step - loss: 3186.5110 - mae: 3186.5110\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3186.510986328125, 3186.510986328125]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "# Create random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Build the model\n",
        "insurance_model_3=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001*10),\n",
        "                          metrics=\"mae\")\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_3.fit(X_train,y_train,epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwXrabgBUokb",
        "outputId": "b55cf894-0c7e-4009-f841-8d430c2e1971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 2s 4ms/step - loss: 8089.0215 - mae: 8089.0215\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6284.0674 - mae: 6284.0674\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 5271.0190 - mae: 5271.0190\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 4879.2812 - mae: 4879.2812\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4315.3066 - mae: 4315.3066\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4161.9038 - mae: 4161.9038\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3997.5154 - mae: 3997.5154\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4118.8652 - mae: 4118.8652\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4043.4541 - mae: 4043.4541\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3843.4854 - mae: 3843.4854\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3823.5437 - mae: 3823.5437\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3708.2114 - mae: 3708.2114\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3745.9392 - mae: 3745.9392\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3914.2075 - mae: 3914.2075\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3918.5149 - mae: 3918.5149\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3975.6375 - mae: 3975.6375\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3911.6301 - mae: 3911.6301\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3786.5938 - mae: 3786.5938\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4489.4355 - mae: 4489.4355\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3993.2751 - mae: 3993.2751\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4279.4077 - mae: 4279.4077\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3895.1638 - mae: 3895.1638\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3842.3342 - mae: 3842.3342\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3748.6628 - mae: 3748.6628\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3827.3328 - mae: 3827.3328\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4043.1416 - mae: 4043.1416\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3896.9348 - mae: 3896.9348\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4083.2014 - mae: 4083.2014\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3787.6057 - mae: 3787.6057\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4068.9897 - mae: 4068.9897\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4058.9285 - mae: 4058.9285\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3857.7131 - mae: 3857.7131\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3853.4507 - mae: 3853.4507\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3898.8994 - mae: 3898.8994\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3778.9617 - mae: 3778.9617\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4060.3159 - mae: 4060.3159\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3864.6931 - mae: 3864.6931\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4255.1270 - mae: 4255.1270\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4033.8350 - mae: 4033.8350\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3774.9338 - mae: 3774.9338\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3873.3394 - mae: 3873.3394\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4055.2000 - mae: 4055.2000\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3712.3279 - mae: 3712.3279\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3747.0991 - mae: 3747.0991\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3674.1440 - mae: 3674.1440\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3725.9194 - mae: 3725.9194\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3828.9143 - mae: 3828.9143\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3881.3955 - mae: 3881.3955\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3710.7341 - mae: 3710.7341\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3977.9612 - mae: 3977.9612\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3795.9832 - mae: 3795.9832\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3777.8125 - mae: 3777.8125\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3597.8203 - mae: 3597.8203\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3908.7759 - mae: 3908.7759\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4064.1646 - mae: 4064.1646\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4124.3379 - mae: 4124.3379\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3884.6582 - mae: 3884.6582\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3795.0767 - mae: 3795.0767\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3739.6843 - mae: 3739.6843\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3721.5535 - mae: 3721.5535\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3788.2161 - mae: 3788.2161\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3683.8232 - mae: 3683.8232\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3620.2393 - mae: 3620.2393\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3633.7126 - mae: 3633.7126\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3658.2971 - mae: 3658.2971\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3915.0703 - mae: 3915.0703\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3667.0930 - mae: 3667.0930\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3993.3901 - mae: 3993.3901\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3775.4871 - mae: 3775.4871\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3963.2729 - mae: 3963.2729\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3884.0659 - mae: 3884.0659\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3838.9053 - mae: 3838.9053\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3766.8723 - mae: 3766.8723\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3682.1414 - mae: 3682.1414\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3708.1516 - mae: 3708.1516\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3685.7166 - mae: 3685.7166\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3667.5149 - mae: 3667.5149\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4034.9258 - mae: 4034.9258\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4084.6416 - mae: 4084.6416\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3810.5010 - mae: 3810.5010\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3811.1296 - mae: 3811.1296\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3764.7075 - mae: 3764.7075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating insurance_model_3\n",
        "insurance_model_3.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "DThP4EzpUsnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What happens if you train for longer (say 300 epochs instead of 200)\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build our model\n",
        "insurance_model_4=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile our model\n",
        "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001*10),\n",
        "                          metrics=\"mae\")\n",
        "\n",
        "# Fit our model\n",
        "insurance_model_4.fit(X_train,y_train,epochs=300)"
      ],
      "metadata": {
        "id": "5MjipXHHUx-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating insurance_model_4\n",
        "insurance_model_4.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "N30q3yrkU0ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing our data before putting it into our best model which insurance_model_2"
      ],
      "metadata": {
        "id": "81MK3scOU3Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insurance.head()"
      ],
      "metadata": {
        "id": "UweDcwxHTAJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing MinMaxScaler,OneHotEncoder and make_column_transformer from sklearn library in order to be able to normalize data\n",
        "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder \n",
        "from sklearn.compose import make_column_transformer"
      ],
      "metadata": {
        "id": "aiGUVztHU_9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a column transformer\n",
        "ct= make_column_transformer(\n",
        "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]),\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"),[\"sex\",\"smoker\",\"region\"])\n",
        ")\n",
        "\n",
        "# Creating X & y values\n",
        "X=insurance.drop(\"charges\",axis=1)\n",
        "y=insurance[\"charges\"]\n",
        "\n",
        "# Building training and test data\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "# Fitting the column transformer on our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transforming training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal=ct.transform(X_train)\n",
        "X_test_normal=ct.transform(X_test)"
      ],
      "metadata": {
        "id": "8HLTekVBVDQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normal[0]"
      ],
      "metadata": {
        "id": "VjFx9B6xVIBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building same model as insurance_model_2\n",
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Build the model\n",
        "insurance_model_5=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(200),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "insurance_model_5.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=\"mae\")\n",
        "\n",
        "# 4. Fit the model\n",
        "history=insurance_model_5.fit(X_train_normal,y_train,epochs=200)"
      ],
      "metadata": {
        "id": "cMJuTafLVLcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating insurance_model_5\n",
        "insurance_model_5.evaluate(X_test_normal,y_test)"
      ],
      "metadata": {
        "id": "zQDYlc0tVPKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting loss curve against epochs\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel=\"Loss curve\"\n",
        "plt.Xlabel=\"Epochs\""
      ],
      "metadata": {
        "id": "GYxqt88vVUG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it."
      ],
      "metadata": {
        "id": "KdYM2H3IVXnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing boston pricing data from Keras datasets\n",
        "(X_train,y_train),(X_test,y_test)=tf.keras.datasets.boston_housing.load_data(path=\"boston_housing.npz\",test_split=0.2,seed=42)"
      ],
      "metadata": {
        "id": "BKsH7RXFVeis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This array is in numpy array format and it is normalized"
      ],
      "metadata": {
        "id": "hFn8shyiVk3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building training and test set\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "8QHgu4MEU-_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a model\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Build our model\n",
        "boston_model=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile our model\n",
        "boston_model.compile(loss=tf.keras.losses.mae,\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=\"mae\")\n",
        "\n",
        "# 3. Fit the model\n",
        "boston_model.fit(X_train,y_train,epochs=100)"
      ],
      "metadata": {
        "id": "lmDRHIdCVxeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating boston_model\n",
        "boston_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "Hibd18ZmV2Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve boston_model by increasing hidden layers, changing optimizer to Adam with lr of 0.01 and give the model more time to learn\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Build our model\n",
        "boston_model_2=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile our model\n",
        "boston_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                       optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                       metrics=\"mae\")\n",
        "\n",
        "# 3. Fit the model\n",
        "history=boston_model_2.fit(X_train,y_train,epochs=300)"
      ],
      "metadata": {
        "id": "gL1QLMXKV6VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating boston_model_2\n",
        "boston_model_2.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "IUdJnZfKV9mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting loss curve against epochs\n",
        "pd.DataFrame(history.history).plot()"
      ],
      "metadata": {
        "id": "zoLTnppYWB8L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}